{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59710030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import matplotlib as mpl\n",
    "from math import floor\n",
    "import scipy\n",
    "from scipy.integrate import quad\n",
    "from scipy.special import gamma\n",
    "from sympy import *\n",
    "from math import floor\n",
    "from scipy.stats import cauchy\n",
    "import scipy\n",
    "import sympy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "177faefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First I will implement 3 dispersal kernels: normal distribution, exponential with c=0.3,  exponential  \n",
    "def standard_normal(x,sigma2):\n",
    "    sigma=float(np.sqrt(sigma2))\n",
    "    exponent = -((x - 0) ** 2) / (2 * sigma ** 2)\n",
    "    return (float(1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(exponent))\n",
    "\n",
    "\n",
    "def return_alpha_for_sigma2(sigma_2,c): # this function returns the alpha which controls the variance of the double exponential distribution\n",
    "    #the exact function to calculate alpha depends on the c parameter. I obtained these functions by solving the variance for the \n",
    "    # distribution analyticially\n",
    "    if(c==0.7):\n",
    "        alpha=symbols('alpha')\n",
    "\n",
    "        f2=9.80495273221691*(alpha)**3.0/alpha\n",
    "        sols=solve(f2 -sigma_2, alpha)\n",
    "\n",
    "\n",
    "    if(c==0.3):\n",
    "        alpha=symbols('alpha')\n",
    "\n",
    "        f2=130618.898293676*(alpha)**3.0/alpha\n",
    "        sols=solve(f2 -sigma_2, alpha)\n",
    "\n",
    "    return(float(sols[1]))\n",
    "\n",
    "def fat_tail(x,alpha,c):\n",
    "    return(float((1)*(c/(2*alpha*(gamma(1/c))))*exp(-Pow(abs((x/alpha)),c))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caa10ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_matrix_any_distribution(f,dispersal_parms,mode): #this function takes a dispersal distribution and stepsize and create \n",
    "    #the migration matrix for over 1000 stepping  stones\n",
    "    step_size=0.5 #The stepsize is 0.5 meaning that every 0.5 steps I create a deme from -500 to 500\n",
    "    steps=np.arange(-501+step_size,501,step_size)\n",
    "    jump_distribution=np.array([])\n",
    "\n",
    "    for i in range(0,len(steps)):\n",
    "        \n",
    "        if(mode==1):\n",
    "            prob=scipy.integrate.quad(f,steps[i]-((step_size)/2),steps[i]+((step_size)/2),args=(dispersal_parms[0]))[0]\n",
    "        if(mode==2):\n",
    "            prob=scipy.integrate.quad(f,steps[i]-((step_size)/2),steps[i]+((step_size)/2),args=(dispersal_parms[0],0.3))[0]\n",
    "        if(mode==3):\n",
    "            prob=scipy.integrate.quad(f,steps[i]-((step_size)/2),steps[i]+((step_size)/2),args=(dispersal_parms[0],0.7))[0]\n",
    "\n",
    "        jump_distribution=np.append(jump_distribution,prob)\n",
    "\n",
    "\n",
    "    dict_normal={}\n",
    "\n",
    "    for i in range(len(jump_distribution)):\n",
    "        dict_normal[round(steps[i],1)]=jump_distribution[i]\n",
    "\n",
    "    mat_new=np.zeros([len(steps),len(steps)])\n",
    "    mapper={}\n",
    "\n",
    "    for i in range(len(steps)): \n",
    "        mapper[i]=round(steps[i],1)\n",
    "    mapper2={}\n",
    "\n",
    "    for i in range(len(steps)):\n",
    "        mapper2[round(steps[i],1)]=i\n",
    "\n",
    "    bound1=steps[0]\n",
    "    bound2=steps[len(steps)-1]\n",
    "\n",
    "    for i in range(len(steps)):\n",
    "        cur_loc=mapper[i]     #this is in cartisian coordiante\n",
    "        prob_row=[0]*len(steps)\n",
    "        for m in range(len(dict_normal)):\n",
    "            jump=round(steps[m],1)\n",
    "\n",
    "            if(jump+cur_loc>bound2 or jump+cur_loc< bound1):\n",
    "                jump=jump*-1 #reflect\n",
    "                new_loc=round(jump+cur_loc,1)\n",
    "                index=mapper2[new_loc]\n",
    "                \n",
    "                prob_row[index]+=dict_normal[jump]\n",
    "            else:\n",
    "                jump=jump #reflect\n",
    "                new_loc=round(jump+cur_loc,1)\n",
    "                index=mapper2[new_loc]\n",
    "                prob_row[index]+=dict_normal[jump]\n",
    "\n",
    "        mat_new[i,:]=prob_row\n",
    "    return(mat_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "135d1f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_seleciton2(x,boundary):\n",
    "    \n",
    "    if x>(boundary+10*2):\n",
    "        return(0.015)\n",
    "    \n",
    "    \n",
    "    if x<(boundary-10*2): #i am multiplying by 2 because i am making steps every 0.5\n",
    "        \n",
    "        return(0.015)\n",
    "\n",
    "    else:\n",
    "       return(-0.015)\n",
    "\n",
    "\n",
    "def s_seleciton3(x,boundary):\n",
    "    \n",
    "    if x>(boundary+10*2):\n",
    "        return(-0.015)\n",
    "    \n",
    "    \n",
    "    if x<(boundary-10*2): #i am multiplying by 2 because i am making steps every 0.5\n",
    "        \n",
    "        return(-0.015)\n",
    "\n",
    "    else:\n",
    "       return(0.015)\n",
    "\n",
    "\n",
    "\n",
    "def s_seleciton1(x,boundary):\n",
    "    \n",
    "    if x>(boundary):\n",
    "        return(0.015)\n",
    "    \n",
    "    \n",
    "    if x<(boundary): #i am multiplying by 2 because i am making steps every 0.5\n",
    "        \n",
    "        return(-0.015)\n",
    "\n",
    "    else:\n",
    "       return(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7261fa6f",
   "metadata": {},
   "source": [
    "1- workflow figure and model\n",
    "\n",
    "2- figure for the approximation for seleciton landscape 1 \n",
    "\n",
    "3- figure for appxoimation for seleciton landscape 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38623c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class deme: #here I am creating an object named deme which has\n",
    "    def __init__(self,location,intial_p):\n",
    "        \n",
    "        self.loc=location\n",
    "        \n",
    "        self.p=intial_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "292326de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is function that updates allele frequency by applying selection and migrations for each deme using matrix multiplication.\n",
    "def update_allele_freqs(population,migration_matrix,s_selection):\n",
    "    #apply_selection\\\n",
    "    allele_freqs=[]\n",
    "    \n",
    "    boundary=floor(len(population)/2)\n",
    "    for i in range(len(population)):#loop through each deme\n",
    "\n",
    "    \n",
    "        allele_freq=population[i].p\n",
    "        allele_freq=allele_freq+s_selection(i,boundary)*(allele_freq*(1-allele_freq)) # apply additive selection equation on each deme \n",
    "        allele_freqs.append(allele_freq)\n",
    "\n",
    "        \n",
    "    new_allele_freqs=np.dot(migration_matrix,allele_freqs)     # multiply the migration matrix nxn with the array of demes nx1 to get new\n",
    "                                                                #allele frequency at each deme after contribution from neighbours \n",
    "    \n",
    "    for i in range(len(population)):\n",
    "\n",
    "            population[i].p=new_allele_freqs[i]\n",
    "            \n",
    "\n",
    "    return(population)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faee279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_cline(input_sigma2,dispersal_mode,s_seleciton): #output is #currently dispersal mode is 1(normal) or 2(c=0.3) or 3(c=0.7) \n",
    "    \n",
    "    \n",
    "    if(dispersal_mode==1):\n",
    "        migration_matrix=make_matrix_any_distribution(standard_normal,[input_sigma2],dispersal_mode)\n",
    "    elif(dispersal_mode==2):\n",
    "        alpha=return_alpha_for_sigma2(input_sigma2,0.3) #for c=0.3 which is very fat tailled\n",
    "        migration_matrix=make_matrix_any_distribution(fat_tail,[alpha],dispersal_mode)\n",
    "\n",
    "    elif(dispersal_mode==3):\n",
    "        alpha=return_alpha_for_sigma2(input_sigma2,0.7) #for c=0.3 which is very fat tailled\n",
    "        migration_matrix=make_matrix_any_distribution(fat_tail,[alpha],dispersal_mode)\n",
    "\n",
    "    \n",
    "    \n",
    "    #Create the intial habitat\n",
    "    habitat=[]\n",
    "    n_demes=len(migration_matrix)\n",
    "    for i in range(0,n_demes):\n",
    "        new_deme=deme(i,0.1)\n",
    "        habitat.append(new_deme)\n",
    "\n",
    "    \n",
    "    cur_pop=deepcopy(habitat)\n",
    "    for gen in range(0,2000): # i just keep updating allele frequency every generation\n",
    "    \n",
    "        cur_pop=update_allele_freqs(cur_pop,migration_matrix,s_seleciton)\n",
    "    \n",
    "    \n",
    "    allele_freqs=[]\n",
    "    for d in cur_pop:\n",
    "        allele_freqs.append(d.p)\n",
    "        \n",
    "        \n",
    "    converted_allele_frequencies={} #here i am mapping the simulated to a discrete scale from from -500 to 500 \n",
    "\n",
    "    x_cords=list(range(-500,501))\n",
    "    index=0\n",
    "    for i in range(0,len(allele_freqs)-2,2):\n",
    "    \n",
    "        converted_allele_frequencies[x_cords[index]]=(allele_freqs[i]+allele_freqs[i+1])/2\n",
    "        index=index+1\n",
    "\n",
    "    \n",
    "    return(allele_freqs,converted_allele_frequencies) #returns the final population on the cline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1920070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# a function to write allele frequency data to csv for plotting in R\n",
    "def write_csv_from_dict(data_dict, filename):\n",
    "    with open(filename, 'w', newline='') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=['x_cords', 'allele_frequency'])\n",
    "        writer.writeheader()\n",
    "        for key, value in data_dict.items():\n",
    "            writer.writerow({'x_cords': key, 'allele_frequency': value})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b9ba975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here I am preparing the population to a table to be directly comparable with the approximation \n",
    "#note that  we have a deme every 0.5 unit length of x axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d629724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_deme_af,population_xcords_af=simulate_cline(4,2,s_seleciton1) # first argument is variance second argument is dispersal mode \n",
    "# 1 is for normal \n",
    "#2 is for c=0.3 on modified double exponential\n",
    "#3 is for c=0.7 on modified double exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f4ecd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv_from_dict(population_xcords_af,\"s1_4_03.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cad7ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
